{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "430a9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8b0d920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "from minitorch.tensor.tensor import Tensor\n",
    "from minitorch.autograd.autograd import (AddBackward,\n",
    "                            MulBackward,\n",
    "                            MatMulBackward,\n",
    "                            DivBackward,\n",
    "                            SubBackward,\n",
    "                            TransposeBackward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d47237de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor(data, requires_grad=True):\n",
    "    \"\"\"create a tensor using the Tensor class\n",
    "\n",
    "    Args:\n",
    "        data (list,ndarray): data to use to create the tensor\n",
    "        requires_grad (bool, optional): _description_. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: N-dimension tensor array storing the data\n",
    "    \"\"\"\n",
    "    return Tensor(np.array(data, dtype= np.float32), requires_grad=requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e5a80fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data=[1. 1.]) Tensor(data=[1. 1.])\n",
      "Tensor(data=[0. 0.]) Tensor(data=[1. 1.])\n"
     ]
    }
   ],
   "source": [
    "def test_add_backward_basic():\n",
    "    a = tensor([1.0, 2.0])\n",
    "    b = tensor([3.0, 4.0])\n",
    "    grad_out = tensor([1.0, 1.0], requires_grad=False)\n",
    "\n",
    "    fn = AddBackward(a, b)\n",
    "    grad_a, grad_b = fn(grad_out)\n",
    "    print(grad_a, grad_b)\n",
    "\n",
    "    np.testing.assert_allclose(grad_a.data, grad_out.data)\n",
    "    np.testing.assert_allclose(grad_b.data, grad_out.data)\n",
    "\n",
    "\n",
    "def test_add_backward_requires_grad_respected():\n",
    "    a = tensor([1.0, 2.0], requires_grad=False)\n",
    "    b = tensor([3.0, 4.0], requires_grad=True)\n",
    "    grad_out = tensor([1.0, 1.0], requires_grad=False)\n",
    "\n",
    "    fn = AddBackward(a, b)\n",
    "    grad_a, grad_b = fn(grad_out)\n",
    "    print(grad_a, grad_b)\n",
    "    \n",
    "    test_grad = Tensor(np.zeros_like(a.data))\n",
    "    \n",
    "    np.testing.assert_allclose(grad_a.data, test_grad.data)\n",
    "    np.testing.assert_allclose(grad_b.data, grad_out.data)\n",
    "\n",
    "\n",
    "def test_add_backward_invalid_input():\n",
    "    with pytest.raises(AssertionError):\n",
    "        fn = AddBackward(1, 2)\n",
    "        fn(tensor(1.0))\n",
    "        \n",
    "test_add_backward_basic()\n",
    "test_add_backward_requires_grad_respected()\n",
    "test_add_backward_invalid_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f322a461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data=[1. 1.]) Tensor(data=[-1. -1.])\n",
      "Tensor(data=[0. 0.]) Tensor(data=[0. 0.])\n"
     ]
    }
   ],
   "source": [
    "def test_sub_backward_basic():\n",
    "    a = tensor([1.0, 2.0])\n",
    "    b = tensor([3.0, 4.0])\n",
    "    grad_out = tensor([1.0, 1.0], requires_grad=False)\n",
    "\n",
    "    fn = SubBackward(a, b)\n",
    "    grad_a, grad_b = fn(grad_out)\n",
    "    print(grad_a, grad_b)\n",
    "    \n",
    "\n",
    "    np.testing.assert_allclose(grad_a.data, grad_out.data)\n",
    "    np.testing.assert_allclose(grad_b.data, -grad_out.data)\n",
    "\n",
    "\n",
    "def test_sub_backward_requires_grad_respected():\n",
    "    a = tensor([1.0, 2.0], requires_grad=False)\n",
    "    b = tensor([3.0, 4.0], requires_grad=False)\n",
    "    grad_out = tensor([1.0, 1.0], requires_grad=False)\n",
    "\n",
    "    fn = AddBackward(a, b)\n",
    "    grad_a, grad_b = fn(grad_out)\n",
    "    test_grad = Tensor(np.zeros_like(a.data))\n",
    "    print(grad_a, grad_b)\n",
    "    np.testing.assert_allclose(grad_a.data, test_grad.data)\n",
    "    np.testing.assert_allclose(grad_b.data, test_grad.data)\n",
    "\n",
    "\n",
    "def test_add_backward_invalid_input():\n",
    "    with pytest.raises(AssertionError):\n",
    "        fn = SubBackward(1, 2)\n",
    "        fn(tensor(1.0))\n",
    "   \n",
    "test_sub_backward_basic()\n",
    "test_sub_backward_requires_grad_respected()\n",
    "test_add_backward_invalid_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a17817a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data=[10.  4.]) Tensor(data=[-30.  -8.])\n",
      "Tensor(data=[0. 0.]) Tensor(data=[-1.5 -0.5])\n"
     ]
    }
   ],
   "source": [
    "def test_div_backward_basic():\n",
    "    a = tensor([6.0, 8.0])\n",
    "    b = tensor([2.0, 4.0])\n",
    "    grad_out = tensor([20.0, 16.0], requires_grad=False)\n",
    "\n",
    "    fn = DivBackward(a, b)\n",
    "    grad_a, grad_b = fn(grad_out)\n",
    "    print(grad_a, grad_b)\n",
    "    \n",
    "    np.testing.assert_allclose(\n",
    "        grad_a.data,\n",
    "        grad_out.data / b.data\n",
    "    )\n",
    "\n",
    "    np.testing.assert_allclose(\n",
    "        grad_b.data,\n",
    "        -grad_out.data * a.data / (b.data ** 2)\n",
    "    )\n",
    "\n",
    "\n",
    "def test_div_backward_requires_grad_respected():\n",
    "    a = tensor([6.0, 8.0], requires_grad=False)\n",
    "    b = tensor([2.0, 4.0], requires_grad=True)\n",
    "    grad_out = tensor([1.0, 1.0], requires_grad=False)\n",
    "\n",
    "    fn = DivBackward(a, b)\n",
    "    grad_a, grad_b = fn(grad_out)\n",
    "    test_grad = Tensor(np.zeros_like(grad_out.data))\n",
    "    print(grad_a, grad_b)\n",
    "\n",
    "    np.testing.assert_allclose(grad_a.data, test_grad.data)\n",
    "    np.testing.assert_allclose(\n",
    "        grad_b.data,\n",
    "        -grad_out.data * a.data / (b.data ** 2)\n",
    "    )\n",
    "    \n",
    "test_div_backward_basic()\n",
    "test_div_backward_requires_grad_respected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eb31c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tensor(data=[[20. 18.]\n",
      " [16. 12.]], shape=(2, 2), grad_info= None),)\n",
      "Tensor(data=[[20. 18.]\n",
      " [16. 12.]])\n"
     ]
    }
   ],
   "source": [
    "def test_transpose_backward_basic():\n",
    "    a = tensor([[6.0, 8.0], [2.0, 4.0]])\n",
    "    # b = tensor([2.0, 4.0])\n",
    "    grad_out = tensor([[20.0, 16.0], [18.0, 12.0]], requires_grad=False)\n",
    "\n",
    "    fn = TransposeBackward(a,0,1)\n",
    "    grad_a = fn(grad_out)\n",
    "    test_grad = grad_out.transpose(0,1)\n",
    "    \n",
    "    print(grad_a)\n",
    "    print(test_grad)\n",
    "    np.testing.assert_allclose(\n",
    "        grad_a[0].data,\n",
    "        test_grad.data\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "test_transpose_backward_basic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d8350691",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor.__init__() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgrad\n",
      "\u001b[1;31mTypeError\u001b[0m: Tensor.__init__() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "Tensor().grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c2e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_autograd(quiet=False):\n",
    "    #* GUARD: prevent double patching\n",
    "    if hasattr(Tensor, '_autograd_enabled'):\n",
    "        #* silently return the tensor if already enable - no need to warn \n",
    "        return \n",
    "    \n",
    "    #*======= STEP 1 : Add gradient infrastructure to tensor ========\n",
    "    _original_init = Tensor.__init__ # store the original init to extend it\n",
    "\n",
    "    def gradient_aware_init(self, data, requires_gradient=False):\n",
    "        \"\"\"Extend Tensor init to support gradinet tracking\"\"\"\n",
    "        _original_init(self, data)\n",
    "        self.requires_grad = requires_gradient\n",
    "        self.grad = None\n",
    "        \n",
    "    Tensor.__init__ = gradient_aware_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a13e8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_original_init = Tensor.__init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "13daaf9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _original_init(\u001b[38;5;28;43mself\u001b[39;49m,data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "_original_init(self,data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinytorch (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
