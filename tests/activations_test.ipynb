{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "047d465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "69a9801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from minitorch.tensor.tensor import Tensor\n",
    "from minitorch.activations.activations import Sigmoid, Softmax, ReLU, GELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "76a851b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.16702503, 0.1847495 , 0.25440598, 0.15112197, 0.36975327]],\n",
       "       dtype=float32),\n",
       " array([[-0.03974773, -0.0507222 , -0.01423913],\n",
       "        [-0.00802161, -0.0102364 , -0.00287364],\n",
       "        [ 0.36508614,  0.4658875 ,  0.1307876 ],\n",
       "        [ 0.3421488 ,  0.4366171 ,  0.12257059],\n",
       "        [-0.18128945, -0.23134398, -0.0649447 ]], dtype=float32),\n",
       " array([0.17627436, 0.22494422, 0.06314811], dtype=float32),\n",
       " array([[0.17627436, 0.22494422, 0.06314811]], dtype=float32),\n",
       " array([[1., 1., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Tensor(np.random.randn(1,5), requires_grad=True)\n",
    "weight = Tensor(np.random.rand(5,3), requires_grad=True)\n",
    "bias = Tensor(np.random.randn(3,), requires_grad=True)\n",
    "\n",
    "y = x @ weight + bias\n",
    "fn = Sigmoid()\n",
    "Z = fn(y)\n",
    "Z.backward()\n",
    "x.grad, weight.grad, bias.grad, y.grad, Z.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "84957524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.63602126, 0.48714876, 0.40150025, 0.5550873 , 0.5727482 ]],\n",
       "       dtype=float32),\n",
       " array([[ 1.9223671e-03,  9.4865704e-01,  1.1731976e-02],\n",
       "        [-3.5940058e-04, -1.7735837e-01, -2.1933788e-03],\n",
       "        [ 3.1652802e-04,  1.5620145e-01,  1.9317325e-03],\n",
       "        [-3.5061690e-04, -1.7302376e-01, -2.1397728e-03],\n",
       "        [-4.0967244e-04, -2.0216672e-01, -2.5001818e-03]], dtype=float32),\n",
       " array([0.00151581, 0.748027  , 0.0092508 ], dtype=float32),\n",
       " array([[0.00151581, 0.748027  , 0.0092508 ]], dtype=float32),\n",
       " array([[1., 1., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = Tensor(np.random.randn(1,5), requires_grad=True)\n",
    "weight1 = Tensor(np.random.rand(5,3), requires_grad=True)\n",
    "bias1 = Tensor(np.random.randn(3,), requires_grad=True)\n",
    "\n",
    "y1 = x1 @ weight1 + bias1\n",
    "fn1 = Softmax()\n",
    "Z1 = fn1(y1)\n",
    "Z1.backward()\n",
    "x1.grad, weight1.grad, bias1.grad, y1.grad, Z1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6cdeb8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[0., 0., 0.]], dtype=float32),\n",
       " array([[1., 1., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = Tensor(np.random.randn(1,5), requires_grad=True)\n",
    "weight2 = Tensor(np.random.rand(5,3), requires_grad=True)\n",
    "bias2 = Tensor(np.random.randn(3,), requires_grad=True)\n",
    "\n",
    "y2 = x2 @ weight2 + bias2\n",
    "fn2 = ReLU()\n",
    "Z2 = fn2(y2)\n",
    "Z2.backward()\n",
    "x2.grad, weight2.grad, bias2.grad, y2.grad, Z2.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "003ea9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.20156571, 0.485451  , 0.53933126, 0.51542985, 0.38058776]],\n",
       "       dtype=float32),\n",
       " array([[-0.87730855,  0.0848358 ,  0.06053137],\n",
       "        [-0.3588411 ,  0.03469996,  0.02475884],\n",
       "        [ 1.9901091 , -0.1924437 , -0.1373109 ],\n",
       "        [-0.76309305,  0.07379116,  0.05265088],\n",
       "        [-1.2981429 ,  0.12553053,  0.08956754]], dtype=float32),\n",
       " array([ 1.0124764 , -0.09790655, -0.06985751], dtype=float32),\n",
       " array([[ 1.0124764 , -0.09790655, -0.06985751]], dtype=float32),\n",
       " array([[1., 1., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = Tensor(np.random.randn(1,5), requires_grad=True)\n",
    "weight3 = Tensor(np.random.rand(5,3), requires_grad=True)\n",
    "bias3 = Tensor(np.random.randn(3,), requires_grad=True)\n",
    "\n",
    "y3 = x3 @ weight3 + bias3\n",
    "fn3 = GELU()\n",
    "Z3 = fn3(y3)\n",
    "Z3.backward()\n",
    "x3.grad, weight3.grad, bias3.grad, y3.grad, Z3.grad\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinytorch (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
