{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "9101419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of minitorch.optimizers.optim failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\babytorch\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 274, in check\n",
      "    superreload(m, reload, self.old_objects, self.shell)\n",
      "  File \"c:\\Users\\User\\Desktop\\babytorch\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\User\\Desktop\\babytorch\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\User\\Desktop\\babytorch\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 330, in update_class\n",
      "    old_obj = getattr(old, key)\n",
      "AttributeError: 'types.GenericAlias' object has no attribute '__copy__'. Did you mean: '__bool__'?\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "a6ec8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from minitorch.tensor.tensor import Tensor\n",
    "from minitorch.optimizers.optim import SGD\n",
    "from minitorch.nn.layers import Linear\n",
    "from minitorch.losses.losses import MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "308650d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sgd_unit_test():\n",
    "#     \"\"\"Test SGD optimizer implemetation\"\"\"\n",
    "#     print('Unit Test: SGD Optimizer ....')\n",
    "    \n",
    "#     #* basic optimizer test\n",
    "#     param = Tensor(np.array([1.0,2.0]), requires_grad=True)\n",
    "#     optimizer = SGD([param], lr=0.1)\n",
    "#     param.grad = Tensor(np.array([2.0, 1.0]))\n",
    "#     original_data = param.data.copy()\n",
    "#     grad = param.grad.data\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     expected = original_data - optimizer.learning_rate * grad\n",
    "#     assert np.allclose(expected.data, param.data)\n",
    "#     assert optimizer.step_count == 1\n",
    "#     print('Basic SGD optimizer works correctly')\n",
    "    \n",
    "#     # optimizer with momentum test\n",
    "#     param2 = Tensor(np.array([1.0, 2.0]), requires_grad=True)\n",
    "#     optimizer_momentum = SGD([param2], lr=0.1, momentum=0.9)\n",
    "#     param2.grad = Tensor(np.array([2.0, 1.0]))\n",
    "#     original_data = param2.data.copy()\n",
    "#     grad = param2.grad.data\n",
    "#     optimizer_momentum.step()\n",
    "    \n",
    "#     expected = original_data - optimizer_momentum.learning_rate * grad\n",
    "#     assert np.allclose(expected.data, param2.data)\n",
    "#     assert optimizer_momentum.step_count == 1, f'step count expected to be 1 got {optimizer_momentum.step_count}'\n",
    "#     print('SGD Oprimizer with momentum works correctly ')\n",
    "    \n",
    "#     # test weight decay\n",
    "#     param3 = Tensor(np.array([1.0, 2.0]), requires_grad=True)\n",
    "#     optimizer_weight_decay = SGD([param3], weight_decay=0.1)\n",
    "#     param3.grad = Tensor(np.array([3.0, 4.0]))\n",
    "    \n",
    "#     optimizer_weight_decay.step()\n",
    "\n",
    "    \n",
    "#     expected = param3.data - optimizer_weight_decay.learning_rate * (param3.grad.data + optimizer_weight_decay.weight_decay * param3.data)\n",
    "#     assert np.allclose(expected, param3.data, rtol=0.05)\n",
    "#     print('SGD Optimizer with weight decay works correctly')\n",
    "    \n",
    "#     print(\"SGD optimizer works correctly!\")\n",
    "\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     sgd_unit_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "b014da18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data=23.954233333333338)\n",
      "Tensor(data=15.597735310885817)\n",
      "Tensor(data=7.002096707620397)\n",
      "Tensor(data=4.674105607992263)\n",
      "Tensor(data=7.856920275163374)\n",
      "Tensor(data=10.861800131680537)\n",
      "Tensor(data=9.590031593006357)\n",
      "Tensor(data=5.204792880398085)\n",
      "Tensor(data=1.9952152162807464)\n",
      "Tensor(data=2.5951306918668124)\n",
      "Tensor(data=5.652310933047676)\n",
      "Tensor(data=7.742104960162236)\n",
      "Tensor(data=6.9255978634190685)\n",
      "Tensor(data=4.26544057419962)\n",
      "Tensor(data=2.244396178997597)\n",
      "Tensor(data=2.171373027081428)\n",
      "Tensor(data=3.220997882883372)\n",
      "Tensor(data=3.6914656795087937)\n",
      "Tensor(data=2.8436365020693852)\n",
      "Tensor(data=1.4482775887802648)\n",
      "Tensor(data=0.7633906755512504)\n",
      "Tensor(data=1.2195169528719865)\n",
      "Tensor(data=2.130818407527852)\n",
      "Tensor(data=2.523027840893184)\n",
      "Tensor(data=2.086099568324145)\n",
      "Tensor(data=1.3256370846635526)\n",
      "Tensor(data=0.9225704881310016)\n",
      "Tensor(data=1.059608800820864)\n",
      "Tensor(data=1.3580346578260494)\n",
      "Tensor(data=1.363532613326002)\n",
      "Tensor(data=1.008738277237916)\n",
      "Tensor(data=0.6128128352027377)\n",
      "Tensor(data=0.5052918797156704)\n",
      "Tensor(data=0.7049881836177958)\n",
      "Tensor(data=0.9518261996647374)\n",
      "Tensor(data=0.9971122981742203)\n",
      "Tensor(data=0.829170819519277)\n",
      "Tensor(data=0.6334335234888008)\n",
      "Tensor(data=0.5762102105140835)\n",
      "Tensor(data=0.6513756599185886)\n",
      "Tensor(data=0.7229959892219938)\n",
      "Tensor(data=0.6845307584300638)\n",
      "Tensor(data=0.5592855437460004)\n",
      "Tensor(data=0.45649257564775275)\n",
      "Tensor(data=0.45183565993676233)\n",
      "Tensor(data=0.5207485492109145)\n",
      "Tensor(data=0.5785794481718621)\n",
      "Tensor(data=0.569812271132096)\n",
      "Tensor(data=0.512760782685829)\n",
      "Tensor(data=0.46618068732056184)\n",
      "Tensor(data=0.46474383421076865)\n",
      "Tensor(data=0.49076824762622423)\n",
      "Tensor(data=0.501994175437563)\n",
      "Tensor(data=0.4778859116496481)\n",
      "Tensor(data=0.4363983332900679)\n",
      "Tensor(data=0.4105158858937399)\n",
      "Tensor(data=0.41439200495442585)\n",
      "Tensor(data=0.43332392589105223)\n",
      "Tensor(data=0.4427112188513708)\n",
      "Tensor(data=0.43262434373697456)\n",
      "Tensor(data=0.4137194474611481)\n",
      "Tensor(data=0.4025842254037216)\n",
      "Tensor(data=0.4044919446809308)\n",
      "Tensor(data=0.41050967110961817)\n",
      "Tensor(data=0.4089329570350684)\n",
      "Tensor(data=0.39732446023851264)\n",
      "Tensor(data=0.38345296908254783)\n",
      "Tensor(data=0.37624901053210064)\n",
      "Tensor(data=0.3772335715474639)\n",
      "Tensor(data=0.38048373712573036)\n",
      "Tensor(data=0.3795707359642195)\n",
      "Tensor(data=0.3735844697297382)\n",
      "Tensor(data=0.36673668201172505)\n",
      "Tensor(data=0.36319423301698256)\n",
      "Tensor(data=0.3630075949339598)\n",
      "Tensor(data=0.3628180791594226)\n",
      "Tensor(data=0.3597513185732583)\n",
      "Tensor(data=0.3541553221203187)\n",
      "Tensor(data=0.3487614529941514)\n",
      "Tensor(data=0.3457186314335859)\n",
      "Tensor(data=0.34471157095081856)\n",
      "Tensor(data=0.3437427965180462)\n",
      "Tensor(data=0.34133098327269035)\n",
      "Tensor(data=0.33777385417039935)\n",
      "Tensor(data=0.3344661429882956)\n",
      "Tensor(data=0.3323078039862877)\n",
      "Tensor(data=0.3309036258632589)\n",
      "Tensor(data=0.3291716681826044)\n",
      "Tensor(data=0.3265116539740075)\n",
      "Tensor(data=0.32330728384276947)\n",
      "Tensor(data=0.3204017834229631)\n",
      "Tensor(data=0.31823318176391246)\n",
      "Tensor(data=0.31651176954394816)\n",
      "Tensor(data=0.31464101174528214)\n",
      "Tensor(data=0.31233974441646745)\n",
      "Tensor(data=0.30983733521602497)\n",
      "Tensor(data=0.3075413278540923)\n",
      "Tensor(data=0.3055990801509485)\n",
      "Tensor(data=0.30379487094307106)\n",
      "Tensor(data=0.30181870259531324)\n"
     ]
    }
   ],
   "source": [
    "x = Tensor(np.array([[2.0, 3.0, 4.6,7.0],\n",
    "                    [4.0,5.0,8.0,10.0],\n",
    "                    [5.6,7.0, 11.1,1.0],\n",
    "                    [2.0, 3.0,0.0,-1.0],\n",
    "                    [4.0,5.0,-2.0, -10.0],\n",
    "                    [5.6,7.0, 11.9,12.0]]), requires_grad=True)\n",
    "y = Tensor(np.array([1.0, 2.0, 3.0, 3.0, 4.0,5.0]), requires_grad=True)\n",
    "\n",
    "weight = Tensor(np.array([0.1, 0.2, 0.3,0.4]), requires_grad=True)\n",
    "bias = Tensor(np.array([0.0,0.0,0.0,0.0,0.0,0.0]), requires_grad=True)\n",
    "\n",
    "loss_fn = MSE()\n",
    "optimizer = SGD([weight, bias],lr=0.001, momentum=0.9, weight_decay=0.01)\n",
    "\n",
    "for _ in range(100):\n",
    "    y_hat = x @ weight.transpose() + bias\n",
    "    loss = loss_fn(y_hat, y)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "1cd666a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(data=[1.54121628 2.69091163 3.16726685 2.54906845 4.12011202 4.11599646], shape=(6,), grad_info= requires_grad=True),\n",
       " Tensor(data=[1. 2. 3. 3. 4. 5.], shape=(6,), grad_info= requires_grad=True))"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = x @ weight.transpose() + bias\n",
    "y_hat,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "d55be76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter(Tensor(data=[[ 2.23806636e-01 -6.93480802e-01  9.10178157e-02 -1.07566191e-01]\n",
      " [ 5.59940188e-01  8.15409005e-01  5.30972344e-01 -6.58918537e-01]\n",
      " [-1.36516000e-01  5.89493667e-01  5.59638519e-02 -6.84906360e-01]\n",
      " [ 9.52927123e-03  6.37203254e-04  1.63910533e-01 -2.23587234e-01]\n",
      " [ 2.83096793e-02 -6.66841412e-02  5.32266039e-01 -9.20956129e-01]\n",
      " [-1.75106919e-01  2.45199212e-01  2.07321417e-01 -4.20151804e-01]]), \n",
      "shape=(6, 4), \n",
      "requires_grad=True, Parameter(Tensor(data=[0. 0. 0. 0. 0. 0.]), \n",
      "shape=(6,), \n",
      "requires_grad=True]\n",
      "Iteration 0, Loss: 27.90892417440996\n",
      "Iteration 1000, Loss: 1.0022412320068266\n",
      "Iteration 2000, Loss: 0.6085088955998402\n",
      "Iteration 3000, Loss: 0.5379183466297079\n",
      "Iteration 4000, Loss: 0.5207227383501065\n",
      "Iteration 5000, Loss: 0.5124181161581789\n",
      "Iteration 6000, Loss: 0.5056610262479426\n",
      "Iteration 7000, Loss: 0.49923875739788254\n",
      "Iteration 8000, Loss: 0.4929500634652341\n",
      "Iteration 9000, Loss: 0.48676058672209366\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(x.shape[1], y.size, bias=True)\n",
    "print(linear.parameters())\n",
    "loss_fn = MSE()\n",
    "optimizer = SGD(linear.parameters(), lr=0.001, momentum=0.0, weight_decay=0.0)\n",
    "# y_hat = x @ weight + bias\n",
    "\n",
    "for i in range(10000):\n",
    "    y_hat = linear(x)\n",
    "    loss = loss_fn(y_hat, y)\n",
    "    if i % 1000 == 0:\n",
    "        print(f'Iteration {i}, Loss: {loss.data}')\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "7d51c483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter(Tensor(data=[[ 0.48110417 -0.08498195 -0.12175056  0.05646291]\n",
       "  [ 0.03533075  0.52003867 -0.19993414  0.08994308]\n",
       "  [-0.22271108  0.98529047 -0.28692736  0.12807139]\n",
       "  [ 0.12952789  0.72307958 -0.30349317  0.13680977]\n",
       "  [ 0.19393939  0.94825717 -0.4056149   0.18292036]\n",
       "  [-0.00521265  1.36971574 -0.4954232   0.22253103]]), \n",
       " shape=(6, 4), \n",
       " requires_grad=True,\n",
       " Parameter(Tensor(data=[0. 0. 0. 0. 0. 0.]), \n",
       " shape=(6,), \n",
       " requires_grad=True]"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "ac625078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data=[2.  3.  4.6 7. ], shape=(4,), grad_info= requires_grad=True)"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinytorch (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
