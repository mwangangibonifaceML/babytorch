{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "9101419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of minitorch.tensor.tensor failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Desktop\\babytorch\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 274, in check\n",
      "    superreload(m, reload, self.old_objects, self.shell)\n",
      "  File \"c:\\Users\\User\\Desktop\\babytorch\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\User\\Desktop\\babytorch\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\User\\Desktop\\babytorch\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 330, in update_class\n",
      "    old_obj = getattr(old, key)\n",
      "AttributeError: 'types.GenericAlias' object has no attribute '__copy__'. Did you mean: '__bool__'?\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "a6ec8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from minitorch.tensor.tensor import Tensor\n",
    "from minitorch.optimizers.optim import SGD\n",
    "from minitorch.nn.layers import Linear\n",
    "from minitorch.losses.losses import MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "308650d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sgd_unit_test():\n",
    "#     \"\"\"Test SGD optimizer implemetation\"\"\"\n",
    "#     print('Unit Test: SGD Optimizer ....')\n",
    "    \n",
    "#     #* basic optimizer test\n",
    "#     param = Tensor(np.array([1.0,2.0]), requires_grad=True)\n",
    "#     optimizer = SGD([param], lr=0.1)\n",
    "#     param.grad = Tensor(np.array([2.0, 1.0]))\n",
    "#     original_data = param.data.copy()\n",
    "#     grad = param.grad.data\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     expected = original_data - optimizer.learning_rate * grad\n",
    "#     assert np.allclose(expected.data, param.data)\n",
    "#     assert optimizer.step_count == 1\n",
    "#     print('Basic SGD optimizer works correctly')\n",
    "    \n",
    "#     # optimizer with momentum test\n",
    "#     param2 = Tensor(np.array([1.0, 2.0]), requires_grad=True)\n",
    "#     optimizer_momentum = SGD([param2], lr=0.1, momentum=0.9)\n",
    "#     param2.grad = Tensor(np.array([2.0, 1.0]))\n",
    "#     original_data = param2.data.copy()\n",
    "#     grad = param2.grad.data\n",
    "#     optimizer_momentum.step()\n",
    "    \n",
    "#     expected = original_data - optimizer_momentum.learning_rate * grad\n",
    "#     assert np.allclose(expected.data, param2.data)\n",
    "#     assert optimizer_momentum.step_count == 1, f'step count expected to be 1 got {optimizer_momentum.step_count}'\n",
    "#     print('SGD Oprimizer with momentum works correctly ')\n",
    "    \n",
    "#     # test weight decay\n",
    "#     param3 = Tensor(np.array([1.0, 2.0]), requires_grad=True)\n",
    "#     optimizer_weight_decay = SGD([param3], weight_decay=0.1)\n",
    "#     param3.grad = Tensor(np.array([3.0, 4.0]))\n",
    "    \n",
    "#     optimizer_weight_decay.step()\n",
    "\n",
    "    \n",
    "#     expected = param3.data - optimizer_weight_decay.learning_rate * (param3.grad.data + optimizer_weight_decay.weight_decay * param3.data)\n",
    "#     assert np.allclose(expected, param3.data, rtol=0.05)\n",
    "#     print('SGD Optimizer with weight decay works correctly')\n",
    "    \n",
    "#     print(\"SGD optimizer works correctly!\")\n",
    "\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     sgd_unit_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "b014da18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,) (6,)\n",
      "Tensor(data=23.954233333333338)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "free variable 'axes' referenced before assignment in enclosing scope",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[512], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_hat, y)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\Desktop\\babytorch\\minitorch\\tensor\\tensor.py:575\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m#* go through the topology in reverse order triggering\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m#* the backward function of each node\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(topo):\n\u001b[1;32m--> 575\u001b[0m     \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\babytorch\\minitorch\\tensor\\tensor.py:536\u001b[0m, in \u001b[0;36mTensor.transpose.<locals>._backward\u001b[1;34m()\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# transpose gradient back\u001b[39;00m\n\u001b[1;32m--> 536\u001b[0m grad_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(result\u001b[38;5;241m.\u001b[39mgrad, \u001b[43maxes\u001b[49m)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m grad_input\n",
      "\u001b[1;31mNameError\u001b[0m: free variable 'axes' referenced before assignment in enclosing scope"
     ]
    }
   ],
   "source": [
    "x = Tensor(np.array([[2.0, 3.0, 4.6,7.0],\n",
    "                    [4.0,5.0,8.0,10.0],\n",
    "                    [5.6,7.0, 11.1,1.0],\n",
    "                    [2.0, 3.0,0.0,-1.0],\n",
    "                    [4.0,5.0,-2.0, -10.0],\n",
    "                    [5.6,7.0, 11.9,12.0]]), requires_grad=True)\n",
    "y = Tensor(np.array([1.0, 2.0, 3.0, 3.0, 4.0,5.0]), requires_grad=True)\n",
    "\n",
    "weight = Tensor(np.array([0.1, 0.2, 0.3,0.4]), requires_grad=True)\n",
    "bias = Tensor(np.array([0.0,0.0,0.0,0.0,0.0,0.0]), requires_grad=True)\n",
    "\n",
    "loss_fn = MSE()\n",
    "optimizer = SGD([weight, bias],lr=0.1, momentum=0.9, weight_decay=0.01)\n",
    "\n",
    "for _ in range(3):\n",
    "    y_hat = x @ weight.transpose() + bias\n",
    "    loss = loss_fn(y_hat, y)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55be76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data=53.01982563683588)\n",
      "Tensor(data=53.01982563683588)\n",
      "Tensor(data=53.01982563683588)\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(x.shape[1], y.size, bias=True)\n",
    "loss_fn = MSE()\n",
    "optimizer = SGD([weight, bias],lr=0.1, momentum=0.9, weight_decay=0.01)\n",
    "# y_hat = x @ weight + bias\n",
    "\n",
    "for _ in range(3):\n",
    "    y_hat = linear(x)\n",
    "    loss = loss_fn(y_hat, y)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce3316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data=[[-4.78016051e+00  2.11982551e+00  1.70305564e-02  3.97588875e+00\n",
       "  -4.77665305e+00  7.39813235e+00]\n",
       " [-8.90038579e+00  2.18849868e+00  3.64234951e-01  5.52875127e+00\n",
       "  -6.89997159e+00  1.12321487e+01]\n",
       " [-1.71946584e+01 -5.05429880e+00  3.36871908e-01 -8.35137895e-01\n",
       "  -3.87440997e+00  3.30026278e+00]\n",
       " [-7.19289773e-01 -3.46260799e+00 -4.34453936e-01 -7.00241011e-01\n",
       "  -2.16355399e+00  2.09064587e-01]\n",
       " [-1.05323265e+00 -1.15737022e+01 -6.50454866e-01 -6.36021968e+00\n",
       "  -5.41532181e-02 -6.89153977e+00]\n",
       " [-1.42881850e+01  1.90741199e+00  5.37684217e-01  6.32622194e+00\n",
       "  -8.62056493e+00  1.37414844e+01]], shape=(6, 6), grad_info= requires_grad=True)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = linear(x)\n",
    "y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinytorch (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
